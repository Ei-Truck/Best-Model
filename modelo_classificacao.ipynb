{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "690589d5",
      "metadata": {},
      "source": [
        "# - Importação de bibliotecas -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0e1cb9aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler,\n",
        "    MinMaxScaler,\n",
        "    LabelEncoder,\n",
        "    OrdinalEncoder,\n",
        "    OneHotEncoder,\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pickle\n",
        "import ast\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "def salvar_melhores(df, nome_base=\"ranking_melhores\", pasta=\".\"):\n",
        "    for modelo in df['Modelo'].unique():\n",
        "        df_modelo = df[df['Modelo'] == modelo]\n",
        "        if not df_modelo.empty:\n",
        "            nome_arquivo = os.path.join(pasta, f\"{nome_base}_{modelo}.csv\")\n",
        "            df.to_csv(nome_arquivo, index=False)\n",
        "            print(f\"Arquivo salvo em: {nome_arquivo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c250b2d",
      "metadata": {},
      "source": [
        "#### Durante esses testes foi definido que o modelo com melhor desempenho foi o Random Forest, levando em consideiração suas metricas, então ele será o utilizado para o modelo preditivo na matéria de ciencias de dados esse modelo, com os parâmetros especificados pelos testes aqui feitos:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c35ca81d",
      "metadata": {},
      "source": [
        "# - Testes -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carregando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GpsProvider</th>\n",
              "      <th>Market/Regular</th>\n",
              "      <th>Origin_Location</th>\n",
              "      <th>Destination_Location</th>\n",
              "      <th>Org_lat_lon</th>\n",
              "      <th>Des_lat_lon</th>\n",
              "      <th>Planned_ETA</th>\n",
              "      <th>Current_Location</th>\n",
              "      <th>DestinationLocation</th>\n",
              "      <th>Curr_lat</th>\n",
              "      <th>Curr_lon</th>\n",
              "      <th>trip_start_date</th>\n",
              "      <th>TRANSPORTATION_DISTANCE_IN_KM</th>\n",
              "      <th>vehicleType</th>\n",
              "      <th>Minimum_kms_to_be_covered_in_a_day</th>\n",
              "      <th>Material Shipped</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CONSENT TRACK</td>\n",
              "      <td>Market</td>\n",
              "      <td>TVSLSL-PUZHAL-HUB,CHENNAI,TAMIL NADU</td>\n",
              "      <td>ASHOK LEYLAND PLANT 1- HOSUR,HOSUR,KARNATAKA</td>\n",
              "      <td>13.1550,80.1960</td>\n",
              "      <td>12.7400,77.8200</td>\n",
              "      <td>2020-08-21 18:59:01</td>\n",
              "      <td>Vaniyambadi Rd, Valayambattu, Tamil Nadu 63575...</td>\n",
              "      <td>ASHOK LEYLAND PLANT 1- HOSUR,HOSUR,KARNATAKA</td>\n",
              "      <td>12.663500</td>\n",
              "      <td>78.649870</td>\n",
              "      <td>2020-08-17 14:59:01</td>\n",
              "      <td>320.0</td>\n",
              "      <td>32 FT Single-Axle 7MT - HCV</td>\n",
              "      <td>250.239362</td>\n",
              "      <td>BRACKET / GRAB HANDLE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VAMOSYS</td>\n",
              "      <td>Regular</td>\n",
              "      <td>DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...</td>\n",
              "      <td>DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...</td>\n",
              "      <td>12.8390,79.9540</td>\n",
              "      <td>12.8390,79.9540</td>\n",
              "      <td>2020-08-31 20:22:22.827000</td>\n",
              "      <td>Unnamed Road, Oragadam Industrial Corridor, Va...</td>\n",
              "      <td>DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...</td>\n",
              "      <td>12.836757</td>\n",
              "      <td>79.954428</td>\n",
              "      <td>2020-08-27 16:21:52</td>\n",
              "      <td>103.0</td>\n",
              "      <td>32 FT Multi-Axle 14MT - HCV</td>\n",
              "      <td>250.239362</td>\n",
              "      <td>ZB MODEL PLATE / 3143</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CONSENT TRACK</td>\n",
              "      <td>Regular</td>\n",
              "      <td>LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY</td>\n",
              "      <td>LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY</td>\n",
              "      <td>11.8710,79.7390</td>\n",
              "      <td>11.8710,79.7390</td>\n",
              "      <td>2020-08-31 21:59:24.987000</td>\n",
              "      <td>570, National Hwy 48, Shenoy Nagar, Chennai, T...</td>\n",
              "      <td>LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY</td>\n",
              "      <td>13.073956</td>\n",
              "      <td>80.225780</td>\n",
              "      <td>2020-08-27 17:57:04</td>\n",
              "      <td>300.0</td>\n",
              "      <td>1 MT Tata Ace (Open Body)</td>\n",
              "      <td>250.239362</td>\n",
              "      <td>LETTERING / FUSO</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VAMOSYS</td>\n",
              "      <td>Regular</td>\n",
              "      <td>DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...</td>\n",
              "      <td>DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...</td>\n",
              "      <td>12.8390,79.9540</td>\n",
              "      <td>12.8390,79.9540</td>\n",
              "      <td>2020-09-01 04:48:24.503000</td>\n",
              "      <td>Singaperumal Koil - Sriperumbudur Rd, Oragadam...</td>\n",
              "      <td>DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...</td>\n",
              "      <td>12.836686</td>\n",
              "      <td>79.950560</td>\n",
              "      <td>2020-08-28 00:47:45</td>\n",
              "      <td>61.0</td>\n",
              "      <td>32 FT Multi-Axle 14MT - HCV</td>\n",
              "      <td>250.239362</td>\n",
              "      <td>LU STRUT RA / RADIUS ROD</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VAMOSYS</td>\n",
              "      <td>Regular</td>\n",
              "      <td>LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY</td>\n",
              "      <td>LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY</td>\n",
              "      <td>11.8720,79.6320</td>\n",
              "      <td>11.8720,79.6320</td>\n",
              "      <td>2020-09-01 05:23:19.243000</td>\n",
              "      <td>Melmaruvathur, Tamil Nadu 603319, India</td>\n",
              "      <td>LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY</td>\n",
              "      <td>12.429501</td>\n",
              "      <td>79.831556</td>\n",
              "      <td>2020-08-28 01:13:48</td>\n",
              "      <td>240.0</td>\n",
              "      <td>32 FT Multi-Axle 14MT - HCV</td>\n",
              "      <td>250.239362</td>\n",
              "      <td>WISHBONE / V ROD/HDT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     GpsProvider Market/Regular   \\\n",
              "0  CONSENT TRACK          Market   \n",
              "1        VAMOSYS         Regular   \n",
              "2  CONSENT TRACK         Regular   \n",
              "3        VAMOSYS         Regular   \n",
              "4        VAMOSYS         Regular   \n",
              "\n",
              "                                     Origin_Location  \\\n",
              "0               TVSLSL-PUZHAL-HUB,CHENNAI,TAMIL NADU   \n",
              "1  DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...   \n",
              "2              LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY   \n",
              "3  DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...   \n",
              "4              LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY   \n",
              "\n",
              "                                Destination_Location      Org_lat_lon  \\\n",
              "0       ASHOK LEYLAND PLANT 1- HOSUR,HOSUR,KARNATAKA  13.1550,80.1960   \n",
              "1  DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...  12.8390,79.9540   \n",
              "2              LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY  11.8710,79.7390   \n",
              "3  DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...  12.8390,79.9540   \n",
              "4              LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY  11.8720,79.6320   \n",
              "\n",
              "       Des_lat_lon                 Planned_ETA  \\\n",
              "0  12.7400,77.8200         2020-08-21 18:59:01   \n",
              "1  12.8390,79.9540  2020-08-31 20:22:22.827000   \n",
              "2  11.8710,79.7390  2020-08-31 21:59:24.987000   \n",
              "3  12.8390,79.9540  2020-09-01 04:48:24.503000   \n",
              "4  11.8720,79.6320  2020-09-01 05:23:19.243000   \n",
              "\n",
              "                                    Current_Location  \\\n",
              "0  Vaniyambadi Rd, Valayambattu, Tamil Nadu 63575...   \n",
              "1  Unnamed Road, Oragadam Industrial Corridor, Va...   \n",
              "2  570, National Hwy 48, Shenoy Nagar, Chennai, T...   \n",
              "3  Singaperumal Koil - Sriperumbudur Rd, Oragadam...   \n",
              "4            Melmaruvathur, Tamil Nadu 603319, India   \n",
              "\n",
              "                                 DestinationLocation   Curr_lat   Curr_lon  \\\n",
              "0       ASHOK LEYLAND PLANT 1- HOSUR,HOSUR,KARNATAKA  12.663500  78.649870   \n",
              "1  DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...  12.836757  79.954428   \n",
              "2              LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY  13.073956  80.225780   \n",
              "3  DAIMLER INDIA COMMERCIAL VEHICLES,KANCHIPURAM,...  12.836686  79.950560   \n",
              "4              LUCAS TVS LTD-PONDY,PONDY,PONDICHERRY  12.429501  79.831556   \n",
              "\n",
              "       trip_start_date  TRANSPORTATION_DISTANCE_IN_KM  \\\n",
              "0  2020-08-17 14:59:01                          320.0   \n",
              "1  2020-08-27 16:21:52                          103.0   \n",
              "2  2020-08-27 17:57:04                          300.0   \n",
              "3  2020-08-28 00:47:45                           61.0   \n",
              "4  2020-08-28 01:13:48                          240.0   \n",
              "\n",
              "                   vehicleType  Minimum_kms_to_be_covered_in_a_day  \\\n",
              "0  32 FT Single-Axle 7MT - HCV                          250.239362   \n",
              "1  32 FT Multi-Axle 14MT - HCV                          250.239362   \n",
              "2    1 MT Tata Ace (Open Body)                          250.239362   \n",
              "3  32 FT Multi-Axle 14MT - HCV                          250.239362   \n",
              "4  32 FT Multi-Axle 14MT - HCV                          250.239362   \n",
              "\n",
              "           Material Shipped  target  \n",
              "0     BRACKET / GRAB HANDLE       0  \n",
              "1     ZB MODEL PLATE / 3143       1  \n",
              "2          LETTERING / FUSO       1  \n",
              "3  LU STRUT RA / RADIUS ROD       1  \n",
              "4      WISHBONE / V ROD/HDT       1  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"base_limpa_1.csv\")\n",
        "\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "y = df.iloc[:, -1] #definindo a ultima como target\n",
        "\n",
        "if y.dtype == \"object\": #se o target for categórico, faz o label encoder\n",
        "    y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Definindo Encoders e Scalers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32a79776",
      "metadata": {},
      "source": [
        "#### Usamos os encoders e scalers que aprendemos em sala de aula, com diferentes casos de uso, para testes mais abrangentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definindo encoders e scalers que vão ser usados nos testes\n",
        "encoders = {\n",
        "    \"OrdinalEncoder\": OrdinalEncoder(), \n",
        "    \"OneHotEncoder\": OneHotEncoder(drop=\"first\", sparse_output=False), \n",
        "    \"GetDummies\": None,\n",
        "}\n",
        "\n",
        "scalers = {\n",
        "    \"StandardScaler\": StandardScaler(),\n",
        "    \"MinMaxScaler\": MinMaxScaler()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Definindo Modelos e Parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "248c6e42",
      "metadata": {},
      "source": [
        "#### **Modelo:** `RandomForestClassifier(class_weight=\"balanced\")`  \n",
        "**Hiperparâmetro avaliado:**\n",
        "- `ccp_alpha`: valores obtidos a partir do caminho de poda de complexidade da árvore  \n",
        "  (`DecisionTreeClassifier(class_weight=\"balanced\").cost_complexity_pruning_path(X_train, y_train)['ccp_alphas'][:-1]`)  \n",
        "\n",
        "O `ccp_alpha` controla a poda de complexidade, reduzindo o overfitting ao eliminar ramos pouco relevantes da floresta.  \n",
        "O uso de `class_weight=\"balanced\"` ajusta automaticamente os pesos das classes, útil para bases desbalanceadas.\n",
        "\n",
        "Tiramos o ultimo valor, porque ele normalmente retorna uma arvore vazia\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **Modelo:** `DecisionTreeClassifier(class_weight=\"balanced\")`  \n",
        "**Hiperparâmetro avaliado:**\n",
        "- `ccp_alpha`: mesmo método utilizado no Random Forest, variando o nível de poda.  \n",
        " \n",
        "O parâmetro `ccp_alpha` define o grau de simplificação da árvore. Valores mais altos geram árvores menores e com menor risco de overfitting,  \n",
        "enquanto valores baixos permitem estruturas mais complexas.  \n",
        "\n",
        "---\n",
        "\n",
        "#### **Modelo:** `SVC()`  \n",
        "**Hiperparâmetros avaliados:**\n",
        "- `C`: [0.1, 1, 10, 100] → controla o trade-off entre margem ampla e erros de classificação.  \n",
        "- `kernel`: ['linear', 'rbf'] → define o tipo de transformação aplicada aos dados.  \n",
        "- `gamma`: ['scale', 'auto'] → controla a influência dos pontos de treino no kernel.  \n",
        "- `degree`: [2, 3, 4] → grau do polinômio (quando kernel='poly').  \n",
        "- `class_weight`: [None, 'balanced'] → corrige desbalanceamento de classes.  \n",
        " \n",
        "Esses parâmetros definem a **forma e flexibilidade do hiperplano de decisão**, buscando o equilíbrio entre generalização e precisão.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Modelo:** `KNeighborsClassifier()`  \n",
        "**Hiperparâmetros avaliados:**\n",
        "- `n_neighbors`: [1, 3, 5, 7, 9, 11, 13, 15] → número de vizinhos considerados.  \n",
        "- `weights`: ['uniform', 'distance'] → define se todos os vizinhos têm o mesmo peso ou se a distância influencia.  \n",
        "- `metric`: ['minkowski', 'manhattan', 'euclidean'] → tipo de distância usada.  \n",
        "- `p`: [1, 2] → parâmetro da distância Minkowski (1 = Manhattan, 2 = Euclidiana).  \n",
        "- `algorithm`: ['auto'] → seleção automática do algoritmo de busca.  \n",
        "  \n",
        "O KNN depende fortemente da métrica de distância e do número de vizinhos.  \n",
        "Esses parâmetros influenciam diretamente a **precisão e robustez** do modelo frente a ruídos.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Modelo:** `MLPClassifier(max_iter=2000, early_stopping=True)`  \n",
        "**Hiperparâmetros avaliados:**\n",
        "- `hidden_layer_sizes`: [(50,), (100,), (50,50), (100,50), (100,100)] → define a arquitetura da rede.  \n",
        "- `activation`: ['relu', 'tanh'] → função de ativação dos neurônios.  \n",
        "- `solver`: ['adam', 'sgd'] → algoritmo de otimização.  \n",
        "- `alpha`: [0.0001, 0.001, 0.01] → regularização L2 para evitar overfitting.  \n",
        "- `learning_rate`: ['constant', 'adaptive'] → define como a taxa de aprendizado é ajustada.  \n",
        "- `learning_rate_init`: [0.001, 0.01] → taxa inicial de aprendizado.  \n",
        "\n",
        "Os hiperparâmetros da MLP definem **a capacidade de aprendizado e generalização** da rede neural.  \n",
        "O uso de `early_stopping=True` evita overtraining, interrompendo o treino quando o desempenho de validação não melhora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definindo os modelos e seus hiperparâmetros pro GridSearch\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_encoded = encoder.fit_transform(X)\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "modelos = {\n",
        "    \"Random Forest\": (\n",
        "        RandomForestClassifier(class_weight=\"balanced\"),\n",
        "        {\n",
        "            'n_estimators': [100, 300, 500],\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'max_features': ['sqrt', 'log2'],\n",
        "            'bootstrap': [True, False],\n",
        "            'class_weight': [None, 'balanced']\n",
        "        },\n",
        "    ),\n",
        "    \"Decision Tree\": (\n",
        "        DecisionTreeClassifier(class_weight=\"balanced\"),\n",
        "        {\n",
        "            'ccp_alpha': DecisionTreeClassifier(class_weight=\"balanced\").cost_complexity_pruning_path(X_train, y_train)['ccp_alphas'][:-1]\n",
        "        },\n",
        "    ),\n",
        "    \"SVM\": (\n",
        "        SVC(),\n",
        "        {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'kernel': ['linear', 'rbf'],\n",
        "            'gamma': ['scale', 'auto'],\n",
        "            'degree': [2, 3, 4],\n",
        "            'class_weight': [None, 'balanced']\n",
        "        },\n",
        "    ),\n",
        "    \"KNN\": (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15],\n",
        "            'weights': ['uniform', 'distance'],\n",
        "            'metric': ['minkowski', 'manhattan', 'euclidean'],\n",
        "            'p': [1, 2],\n",
        "            'algorithm': ['auto']\n",
        "        },\n",
        "    ),\n",
        "    \"MLP Neural Net\": (\n",
        "        MLPClassifier(max_iter=2000, early_stopping=True),\n",
        "        {\n",
        "            'hidden_layer_sizes': [(50,), (100,), (50,50), (100,50), (100,100)],\n",
        "            'activation': ['relu', 'tanh'],\n",
        "            'solver': ['adam', 'sgd'],\n",
        "            'alpha': [0.0001, 0.001, 0.01],\n",
        "            'learning_rate': ['constant', 'adaptive'],\n",
        "            'learning_rate_init': [0.001, 0.01]\n",
        "        },\n",
        "    ),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f7ea73",
      "metadata": {},
      "source": [
        "### 3.1 Separação por modelo (para rodar um por vez) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "315612e8",
      "metadata": {},
      "source": [
        "#### Teste do decision tree com outros parametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae0cb6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Decision Tree\n",
        "modelos = {\n",
        "    \"Decision Tree\": (\n",
        "        DecisionTreeClassifier(class_weight=\"balanced\"),\n",
        "        {\n",
        "            \"criterion\": [\"gini\", \"entropy\"],\n",
        "            \"splitter\": [\"best\", \"random\"],\n",
        "            \"max_depth\": [None, 5, 10],\n",
        "            \"min_samples_split\": [2, 5],\n",
        "            \"min_samples_leaf\": [1, 2],\n",
        "            \"max_features\": [None, \"sqrt\"],\n",
        "        },\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca53a71b",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "modelos = {\n",
        "    \"Random Forest\": (\n",
        "        RandomForestClassifier(class_weight=\"balanced\"),\n",
        "        {\n",
        "            'n_estimators': [100, 300, 500],\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4],\n",
        "            'max_features': ['sqrt', 'log2'],\n",
        "            'bootstrap': [True, False],\n",
        "            'class_weight': [None, 'balanced']\n",
        "        },\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535ade32",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.00000000e+00 1.65321099e-19 1.65321099e-19 1.65321099e-19\n",
            " 1.65321099e-19 1.65321099e-19 1.65321099e-19 1.65321099e-19\n",
            " 4.64140060e-19 6.06177363e-19 1.20676416e-18 1.43278286e-18\n",
            " 1.48524819e-18 1.85656024e-18 2.36960242e-18 2.86556572e-18\n",
            " 2.97049639e-18 4.40856264e-18 9.64373077e-18 1.16344442e-17\n",
            " 1.29317837e-17 3.68836635e-17 4.73920484e-17 1.27583567e-04\n",
            " 1.27583567e-04 1.28723796e-04 1.50557061e-04 1.52518738e-04\n",
            " 1.57654107e-04 1.58227848e-04 1.60115258e-04 1.60683871e-04\n",
            " 1.62840645e-04 1.63762610e-04 1.66648833e-04 1.84325973e-04\n",
            " 2.01714574e-04 2.07641196e-04 2.07641196e-04 2.07641196e-04\n",
            " 2.07641196e-04 2.07641196e-04 2.07641196e-04 2.13160798e-04\n",
            " 2.14568423e-04 2.20026501e-04 2.24356098e-04 2.27582944e-04\n",
            " 2.29080691e-04 2.38526858e-04 2.43170137e-04 2.51372066e-04\n",
            " 2.55167134e-04 2.55167134e-04 2.55167134e-04 2.58010615e-04\n",
            " 2.60427970e-04 2.62983441e-04 2.63792584e-04 2.65023056e-04\n",
            " 2.69634819e-04 2.71666444e-04 2.76243094e-04 2.76527149e-04\n",
            " 2.77160689e-04 2.79383871e-04 2.94177713e-04 2.95527402e-04\n",
            " 2.95787979e-04 2.95787979e-04 2.98430770e-04 3.01114122e-04\n",
            " 3.01114122e-04 3.03826585e-04 3.06471189e-04 3.08047747e-04\n",
            " 3.10430464e-04 3.10430464e-04 3.21367741e-04 3.28611635e-04\n",
            " 3.37324855e-04 3.40028010e-04 3.43445907e-04 3.43445907e-04\n",
            " 3.47677722e-04 3.49976587e-04 3.50387026e-04 3.50720944e-04\n",
            " 3.56972870e-04 3.56972870e-04 3.56972870e-04 3.56972870e-04\n",
            " 3.63344489e-04 3.66667840e-04 3.71209000e-04 3.80284919e-04\n",
            " 3.93650837e-04 4.03030093e-04 4.06894299e-04 4.25287155e-04\n",
            " 4.34404881e-04 4.35224140e-04 4.37093517e-04 4.49293967e-04\n",
            " 4.49900421e-04 4.52781463e-04 4.55569559e-04 4.59599210e-04\n",
            " 4.60458156e-04 4.63817565e-04 4.81283041e-04 4.93625483e-04\n",
            " 4.97440112e-04 4.97463668e-04 5.07159905e-04 5.07159905e-04\n",
            " 5.09712862e-04 5.09712862e-04 5.10334269e-04 5.23395629e-04\n",
            " 5.25118152e-04 5.26812963e-04 5.33776138e-04 5.34816558e-04\n",
            " 5.35635314e-04 5.35870556e-04 5.41692156e-04 5.48031302e-04\n",
            " 5.98411090e-04 6.01636413e-04 6.09470919e-04 6.14358434e-04\n",
            " 6.14920361e-04 6.17449748e-04 6.17500509e-04 6.22461481e-04\n",
            " 6.33810536e-04 6.80541278e-04 6.82575064e-04 6.86722742e-04\n",
            " 7.85934849e-04 8.24234012e-04 8.27392087e-04 8.60267912e-04\n",
            " 8.73737653e-04 9.15055460e-04 9.35019540e-04 1.02962844e-03\n",
            " 1.09223798e-03 1.17077028e-03 1.18255286e-03 1.23041170e-03\n",
            " 1.49296895e-03 1.51795984e-03 1.58588192e-03 1.59115659e-03\n",
            " 1.73624480e-03 1.80619915e-03 2.15938807e-03 2.34503174e-03\n",
            " 3.47758154e-03 3.63780124e-03 4.73376103e-03 4.90211948e-03\n",
            " 5.06435215e-03 5.10119841e-03 6.62298629e-03 1.96621159e-02\n",
            " 3.88999344e-02]\n"
          ]
        }
      ],
      "source": [
        "encoder = OrdinalEncoder()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_encoded = encoder.fit_transform(X)\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "modelos = {\n",
        "    \"Decision Tree\": (\n",
        "        DecisionTreeClassifier(class_weight=\"balanced\"),\n",
        "        {\n",
        "            'ccp_alpha': DecisionTreeClassifier(class_weight=\"balanced\").cost_complexity_pruning_path(X_train, y_train)['ccp_alphas'][:-1]\n",
        "        },\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d629dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "#SVM\n",
        "modelos = {\n",
        "    \"SVM\": (\n",
        "        SVC(),\n",
        "        {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'kernel': ['linear', 'rbf'],\n",
        "            'gamma': ['scale', 'auto'],\n",
        "            'degree': [2, 3, 4],\n",
        "            'class_weight': [None, 'balanced']\n",
        "        },\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58bec6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#KNN\n",
        "modelos = {\n",
        "    \"KNN\": (\n",
        "        KNeighborsClassifier(),\n",
        "        {\n",
        "            'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15],\n",
        "            'weights': ['uniform', 'distance'],\n",
        "            'metric': ['minkowski', 'manhattan', 'euclidean'],\n",
        "            'p': [1, 2],\n",
        "            'algorithm': ['auto']\n",
        "        },\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc36088",
      "metadata": {},
      "outputs": [],
      "source": [
        "#MLP\n",
        "modelos = {\n",
        "    \"MLP Neural Net\": (\n",
        "        MLPClassifier(max_iter=2000, early_stopping=True),\n",
        "        {\n",
        "            'hidden_layer_sizes': [(50,), (100,), (50,50), (100,50), (100,100)],\n",
        "            'activation': ['relu', 'tanh'],\n",
        "            'solver': ['adam', 'sgd'],\n",
        "            'alpha': [0.0001, 0.001, 0.01],\n",
        "            'learning_rate': ['constant', 'adaptive'],\n",
        "            'learning_rate_init': [0.001, 0.01]\n",
        "        },\n",
        "    ),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Loop de Testes com GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ce3e076",
      "metadata": {},
      "source": [
        "#### Testes com `GridSearchCV`\n",
        "\n",
        "#### Fazemos o teste do GridSearchCV, para testar todas as combinações de parametros para cada modelo e repetimos esse teste para cada combinação de encoder e scaler, e colocamos os resultados desses testes em uma lista de dicionarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados = []\n",
        "\n",
        "for enc_name, encoder in encoders.items():\n",
        "    if enc_name == \"GetDummies\":\n",
        "        X_enc = pd.get_dummies(X, drop_first=True)\n",
        "    else:\n",
        "        X_enc = encoder.fit_transform(X)\n",
        "        if isinstance(X_enc, np.ndarray):\n",
        "            X_enc = pd.DataFrame(X_enc)\n",
        "\n",
        "    for sc_name, scaler in scalers.items():\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_enc, y, test_size=0.3, random_state=42\n",
        "        )\n",
        "\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        for model_name, (modelo, param_grid) in modelos.items():\n",
        "            try:\n",
        "                grid = GridSearchCV(\n",
        "                    modelo, param_grid, cv=5, scoring=\"f1_weighted\", n_jobs=-1\n",
        "                )\n",
        "                grid.fit(X_train, y_train)\n",
        "                y_pred = grid.predict(X_test)\n",
        "\n",
        "                resultados.append({\n",
        "                    \"Encoder\": enc_name,\n",
        "                    \"Scaler\": sc_name,\n",
        "                    \"Modelo\": model_name,\n",
        "                    \"Melhores Params\": grid.best_params_,\n",
        "                    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "                    \"Precision\": precision_score(y_test, y_pred, average=\"weighted\"),\n",
        "                    \"Recall\": recall_score(y_test, y_pred, average=\"weighted\"),\n",
        "                    \"F1-Score\": f1_score(y_test, y_pred, average=\"weighted\"),\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                resultados.append({\n",
        "                    \"Encoder\": enc_name,\n",
        "                    \"Scaler\": sc_name,\n",
        "                    \"Modelo\": model_name,\n",
        "                    \"Melhores Params\": None,\n",
        "                    \"Accuracy\": None,\n",
        "                    \"Precision\": None,\n",
        "                    \"Recall\": None,\n",
        "                    \"F1-Score\": None,\n",
        "                    \"Erro\": str(e),\n",
        "                })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Ranking Final dos Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados_df = pd.DataFrame(resultados)\n",
        "melhores = resultados_df.sort_values(by=\"F1-Score\", ascending=False)\n",
        "\n",
        "print(\"Ranking final:\")\n",
        "display(melhores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bfe46f",
      "metadata": {},
      "outputs": [],
      "source": [
        "salvar_melhores(melhores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bceb6044",
      "metadata": {},
      "source": [
        "\n",
        "# - Analise dos resultados dos testes -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a6653b3a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Encoder</th>\n",
              "      <th>Scaler</th>\n",
              "      <th>Modelo</th>\n",
              "      <th>Melhores Params</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Erro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
              "      <td>0.951066</td>\n",
              "      <td>0.951026</td>\n",
              "      <td>0.951066</td>\n",
              "      <td>0.950869</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
              "      <td>0.949128</td>\n",
              "      <td>0.949053</td>\n",
              "      <td>0.949128</td>\n",
              "      <td>0.948940</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.932171</td>\n",
              "      <td>0.932045</td>\n",
              "      <td>0.932171</td>\n",
              "      <td>0.932093</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 10, 'max_fe...</td>\n",
              "      <td>0.931202</td>\n",
              "      <td>0.931165</td>\n",
              "      <td>0.931202</td>\n",
              "      <td>0.931182</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>SVM</td>\n",
              "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
              "      <td>0.923934</td>\n",
              "      <td>0.924448</td>\n",
              "      <td>0.923934</td>\n",
              "      <td>0.923114</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
              "      <td>0.922965</td>\n",
              "      <td>0.924891</td>\n",
              "      <td>0.922965</td>\n",
              "      <td>0.921723</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
              "      <td>0.921996</td>\n",
              "      <td>0.923399</td>\n",
              "      <td>0.921996</td>\n",
              "      <td>0.920862</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>SVM</td>\n",
              "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
              "      <td>0.921512</td>\n",
              "      <td>0.921860</td>\n",
              "      <td>0.921512</td>\n",
              "      <td>0.920708</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>MLP Neural Net</td>\n",
              "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.917189</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.915692</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>MLP Neural Net</td>\n",
              "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.917731</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.915503</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>SVM</td>\n",
              "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
              "      <td>0.916182</td>\n",
              "      <td>0.916989</td>\n",
              "      <td>0.916182</td>\n",
              "      <td>0.915092</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
              "      <td>0.914729</td>\n",
              "      <td>0.917215</td>\n",
              "      <td>0.914729</td>\n",
              "      <td>0.913128</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>KNN</td>\n",
              "      <td>{'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}</td>\n",
              "      <td>0.912306</td>\n",
              "      <td>0.912004</td>\n",
              "      <td>0.912306</td>\n",
              "      <td>0.912089</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'bootstrap': True, 'criterion': 'gini', 'max_...</td>\n",
              "      <td>0.912306</td>\n",
              "      <td>0.914469</td>\n",
              "      <td>0.912306</td>\n",
              "      <td>0.910714</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>KNN</td>\n",
              "      <td>{'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}</td>\n",
              "      <td>0.910368</td>\n",
              "      <td>0.910109</td>\n",
              "      <td>0.910368</td>\n",
              "      <td>0.910200</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>KNN</td>\n",
              "      <td>{'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}</td>\n",
              "      <td>0.907461</td>\n",
              "      <td>0.907190</td>\n",
              "      <td>0.907461</td>\n",
              "      <td>0.907287</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>MLP Neural Net</td>\n",
              "      <td>{'activation': 'tanh', 'alpha': 0.001, 'hidden...</td>\n",
              "      <td>0.907946</td>\n",
              "      <td>0.908307</td>\n",
              "      <td>0.907946</td>\n",
              "      <td>0.906835</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>KNN</td>\n",
              "      <td>{'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}</td>\n",
              "      <td>0.904554</td>\n",
              "      <td>0.904638</td>\n",
              "      <td>0.904554</td>\n",
              "      <td>0.904594</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
              "      <td>0.901647</td>\n",
              "      <td>0.902581</td>\n",
              "      <td>0.901647</td>\n",
              "      <td>0.901975</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
              "      <td>0.900678</td>\n",
              "      <td>0.900226</td>\n",
              "      <td>0.900678</td>\n",
              "      <td>0.900311</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>SVM</td>\n",
              "      <td>{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
              "      <td>0.897771</td>\n",
              "      <td>0.901587</td>\n",
              "      <td>0.897771</td>\n",
              "      <td>0.895250</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': None, 'max_...</td>\n",
              "      <td>0.894864</td>\n",
              "      <td>0.894367</td>\n",
              "      <td>0.894864</td>\n",
              "      <td>0.894475</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
              "      <td>0.893895</td>\n",
              "      <td>0.893756</td>\n",
              "      <td>0.893895</td>\n",
              "      <td>0.893820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>OrdinalEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>MLP Neural Net</td>\n",
              "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
              "      <td>0.891957</td>\n",
              "      <td>0.894135</td>\n",
              "      <td>0.891957</td>\n",
              "      <td>0.889676</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>MLP Neural Net</td>\n",
              "      <td>{'activation': 'relu', 'alpha': 0.001, 'hidden...</td>\n",
              "      <td>0.718508</td>\n",
              "      <td>0.778589</td>\n",
              "      <td>0.718508</td>\n",
              "      <td>0.662318</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>MLP Neural Net</td>\n",
              "      <td>{'activation': 'relu', 'alpha': 0.0001, 'hidde...</td>\n",
              "      <td>0.640988</td>\n",
              "      <td>0.802071</td>\n",
              "      <td>0.640988</td>\n",
              "      <td>0.631796</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>KNN</td>\n",
              "      <td>{'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}</td>\n",
              "      <td>0.648740</td>\n",
              "      <td>0.762188</td>\n",
              "      <td>0.648740</td>\n",
              "      <td>0.524966</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>GetDummies</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>KNN</td>\n",
              "      <td>{'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}</td>\n",
              "      <td>0.644380</td>\n",
              "      <td>0.772083</td>\n",
              "      <td>0.644380</td>\n",
              "      <td>0.514671</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>StandardScaler</td>\n",
              "      <td>SVM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[WinError 1450] Insufficient system resources ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>OneHotEncoder</td>\n",
              "      <td>MinMaxScaler</td>\n",
              "      <td>SVM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[WinError 1450] Insufficient system resources ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Encoder          Scaler          Modelo  \\\n",
              "18  OrdinalEncoder  StandardScaler   Random Forest   \n",
              "19  OrdinalEncoder    MinMaxScaler   Random Forest   \n",
              "0   OrdinalEncoder    MinMaxScaler   Decision Tree   \n",
              "1   OrdinalEncoder  StandardScaler   Decision Tree   \n",
              "24  OrdinalEncoder    MinMaxScaler             SVM   \n",
              "20      GetDummies    MinMaxScaler   Random Forest   \n",
              "21      GetDummies  StandardScaler   Random Forest   \n",
              "25  OrdinalEncoder  StandardScaler             SVM   \n",
              "12      GetDummies    MinMaxScaler  MLP Neural Net   \n",
              "13   OneHotEncoder    MinMaxScaler  MLP Neural Net   \n",
              "26      GetDummies    MinMaxScaler             SVM   \n",
              "22   OneHotEncoder  StandardScaler   Random Forest   \n",
              "6   OrdinalEncoder    MinMaxScaler             KNN   \n",
              "23   OneHotEncoder    MinMaxScaler   Random Forest   \n",
              "7    OneHotEncoder    MinMaxScaler             KNN   \n",
              "8   OrdinalEncoder  StandardScaler             KNN   \n",
              "14  OrdinalEncoder  StandardScaler  MLP Neural Net   \n",
              "9       GetDummies    MinMaxScaler             KNN   \n",
              "2       GetDummies    MinMaxScaler   Decision Tree   \n",
              "3       GetDummies  StandardScaler   Decision Tree   \n",
              "27      GetDummies  StandardScaler             SVM   \n",
              "4    OneHotEncoder  StandardScaler   Decision Tree   \n",
              "5    OneHotEncoder    MinMaxScaler   Decision Tree   \n",
              "15  OrdinalEncoder    MinMaxScaler  MLP Neural Net   \n",
              "16      GetDummies  StandardScaler  MLP Neural Net   \n",
              "17   OneHotEncoder  StandardScaler  MLP Neural Net   \n",
              "10   OneHotEncoder  StandardScaler             KNN   \n",
              "11      GetDummies  StandardScaler             KNN   \n",
              "28   OneHotEncoder  StandardScaler             SVM   \n",
              "29   OneHotEncoder    MinMaxScaler             SVM   \n",
              "\n",
              "                                      Melhores Params  Accuracy  Precision  \\\n",
              "18  {'bootstrap': True, 'criterion': 'gini', 'max_...  0.951066   0.951026   \n",
              "19  {'bootstrap': True, 'criterion': 'gini', 'max_...  0.949128   0.949053   \n",
              "0   {'criterion': 'gini', 'max_depth': 10, 'max_fe...  0.932171   0.932045   \n",
              "1   {'criterion': 'gini', 'max_depth': 10, 'max_fe...  0.931202   0.931165   \n",
              "24       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}  0.923934   0.924448   \n",
              "20  {'bootstrap': True, 'criterion': 'gini', 'max_...  0.922965   0.924891   \n",
              "21  {'bootstrap': True, 'criterion': 'gini', 'max_...  0.921996   0.923399   \n",
              "25       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}  0.921512   0.921860   \n",
              "12  {'activation': 'relu', 'alpha': 0.001, 'hidden...  0.916667   0.917189   \n",
              "13  {'activation': 'relu', 'alpha': 0.0001, 'hidde...  0.916667   0.917731   \n",
              "26       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}  0.916182   0.916989   \n",
              "22  {'bootstrap': True, 'criterion': 'gini', 'max_...  0.914729   0.917215   \n",
              "6    {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}  0.912306   0.912004   \n",
              "23  {'bootstrap': True, 'criterion': 'gini', 'max_...  0.912306   0.914469   \n",
              "7    {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}  0.910368   0.910109   \n",
              "8    {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}  0.907461   0.907190   \n",
              "14  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  0.907946   0.908307   \n",
              "9    {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}  0.904554   0.904638   \n",
              "2   {'criterion': 'gini', 'max_depth': None, 'max_...  0.901647   0.902581   \n",
              "3   {'criterion': 'entropy', 'max_depth': None, 'm...  0.900678   0.900226   \n",
              "27   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}  0.897771   0.901587   \n",
              "4   {'criterion': 'gini', 'max_depth': None, 'max_...  0.894864   0.894367   \n",
              "5   {'criterion': 'entropy', 'max_depth': None, 'm...  0.893895   0.893756   \n",
              "15  {'activation': 'relu', 'alpha': 0.0001, 'hidde...  0.891957   0.894135   \n",
              "16  {'activation': 'relu', 'alpha': 0.001, 'hidden...  0.718508   0.778589   \n",
              "17  {'activation': 'relu', 'alpha': 0.0001, 'hidde...  0.640988   0.802071   \n",
              "10   {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}  0.648740   0.762188   \n",
              "11   {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}  0.644380   0.772083   \n",
              "28                                                NaN       NaN        NaN   \n",
              "29                                                NaN       NaN        NaN   \n",
              "\n",
              "      Recall  F1-Score                                               Erro  \n",
              "18  0.951066  0.950869                                                NaN  \n",
              "19  0.949128  0.948940                                                NaN  \n",
              "0   0.932171  0.932093                                                NaN  \n",
              "1   0.931202  0.931182                                                NaN  \n",
              "24  0.923934  0.923114                                                NaN  \n",
              "20  0.922965  0.921723                                                NaN  \n",
              "21  0.921996  0.920862                                                NaN  \n",
              "25  0.921512  0.920708                                                NaN  \n",
              "12  0.916667  0.915692                                                NaN  \n",
              "13  0.916667  0.915503                                                NaN  \n",
              "26  0.916182  0.915092                                                NaN  \n",
              "22  0.914729  0.913128                                                NaN  \n",
              "6   0.912306  0.912089                                                NaN  \n",
              "23  0.912306  0.910714                                                NaN  \n",
              "7   0.910368  0.910200                                                NaN  \n",
              "8   0.907461  0.907287                                                NaN  \n",
              "14  0.907946  0.906835                                                NaN  \n",
              "9   0.904554  0.904594                                                NaN  \n",
              "2   0.901647  0.901975                                                NaN  \n",
              "3   0.900678  0.900311                                                NaN  \n",
              "27  0.897771  0.895250                                                NaN  \n",
              "4   0.894864  0.894475                                                NaN  \n",
              "5   0.893895  0.893820                                                NaN  \n",
              "15  0.891957  0.889676                                                NaN  \n",
              "16  0.718508  0.662318                                                NaN  \n",
              "17  0.640988  0.631796                                                NaN  \n",
              "10  0.648740  0.524966                                                NaN  \n",
              "11  0.644380  0.514671                                                NaN  \n",
              "28       NaN       NaN  [WinError 1450] Insufficient system resources ...  \n",
              "29       NaN       NaN  [WinError 1450] Insufficient system resources ...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "csv_files = [f for f in os.listdir(\".\") if f.endswith(\".csv\") and f != \"base_limpa_1.csv\"]\n",
        "\n",
        "testes = [pd.read_csv(file) for file in csv_files]\n",
        "df = pd.concat(testes, ignore_index=True)\n",
        "df = df.sort_values(by=\"F1-Score\", ascending=False)\n",
        "\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb9e1638",
      "metadata": {},
      "source": [
        "# - Criando pkl para a melhor combinção de cada modelo -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742f05c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "modelos = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(class_weight=\"balanced\", random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"MLP Neural Net\": MLPClassifier(max_iter=2000, early_stopping=True, random_state=42),\n",
        "}\n",
        "\n",
        "csv_files = [f for f in os.listdir(\".\") if f.endswith(\".csv\") and f != \"base_limpa_1.csv\"]\n",
        "\n",
        "for file in csv_files:\n",
        "    df_result = pd.read_csv(file)\n",
        "    melhor = df_result.sort_values(by=\"F1-Score\", ascending=False).iloc[0]\n",
        "\n",
        "    model_name = melhor[\"Modelo\"]\n",
        "    param_grid = ast.literal_eval(melhor[\"Melhores Params\"])\n",
        "    encoder_name = melhor[\"Encoder\"]\n",
        "    scaler_name = melhor[\"Scaler\"]\n",
        "\n",
        "    df_base = pd.read_csv(\"base_limpa_1.csv\")\n",
        "    X = df_base.iloc[:, :-1].copy()\n",
        "    y = df_base.iloc[:, -1].copy()\n",
        "\n",
        "    if y.dtype == \"object\":\n",
        "        y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "    categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "    ordinal_encoders = {}\n",
        "    onehot_encoders = {}\n",
        "    scaler = None\n",
        "\n",
        "    if encoder_name == \"GetDummies\":\n",
        "        X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "    elif encoder_name == \"OrdinalEncoder\":\n",
        "        for col in categorical_cols:\n",
        "            ordinal = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "            X[col] = ordinal.fit_transform(X[[col]])\n",
        "            ordinal_encoders[col] = ordinal\n",
        "\n",
        "    elif encoder_name == \"OneHotEncoder\":\n",
        "        for col in categorical_cols:\n",
        "            onehot = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "            encoded = onehot.fit_transform(X[[col]])\n",
        "            encoded_df = pd.DataFrame(encoded, columns=[f\"{col}_{i}\" for i in range(encoded.shape[1])], index=X.index)\n",
        "            X = X.drop(columns=[col]).join(encoded_df)\n",
        "            onehot_encoders[col] = (onehot, encoded_df.columns.tolist())\n",
        "\n",
        "    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "    if numerical_cols:\n",
        "        scaler = StandardScaler() if scaler_name == \"StandardScaler\" else MinMaxScaler()\n",
        "        X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        (\"modelo\", modelos[model_name].set_params(**param_grid))\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    dump_obj = {\n",
        "        \"pipeline\": pipeline,\n",
        "        \"encoder_name\": encoder_name,\n",
        "        \"scaler_name\": scaler_name,\n",
        "        \"ordinal_encoders\": ordinal_encoders,\n",
        "        \"onehot_encoders\": onehot_encoders,\n",
        "        \"X_train_columns\": X_train.columns.tolist(),\n",
        "        \"scaler\": scaler\n",
        "    }\n",
        "\n",
        "    nome_pkl = f\"melhor_{model_name.replace(' ', '_')}.pkl\"\n",
        "    with open(nome_pkl, \"wb\") as f:\n",
        "        pickle.dump(dump_obj, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd55feb",
      "metadata": {},
      "source": [
        "### Como carregar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ee4312",
      "metadata": {},
      "outputs": [],
      "source": [
        "def carregar_pipeline(nome_pkl):\n",
        "    with open(nome_pkl, \"rb\") as f:\n",
        "        obj = pickle.load(f)\n",
        "    return obj\n",
        "\n",
        "def prever_com_pipeline(df, obj):\n",
        "    X = df.iloc[:, :-1].copy()\n",
        "    y = df.iloc[:, -1].copy()\n",
        "\n",
        "    encoder_name = obj[\"encoder_name\"]\n",
        "    pipeline = obj[\"pipeline\"]\n",
        "    ordinal_encoders = obj.get(\"ordinal_encoders\", {})\n",
        "    onehot_encoders = obj.get(\"onehot_encoders\", {})\n",
        "    X_train_cols = obj.get(\"X_train_columns\")\n",
        "    scaler = obj.get(\"scaler\")\n",
        "\n",
        "    if encoder_name == \"GetDummies\":\n",
        "        X = pd.get_dummies(X, drop_first=True)\n",
        "        X = X.reindex(columns=X_train_cols, fill_value=0)\n",
        "    elif encoder_name == \"OrdinalEncoder\":\n",
        "        for col, enc in ordinal_encoders.items():\n",
        "            X[col] = enc.transform(X[[col]])\n",
        "    elif encoder_name == \"OneHotEncoder\":\n",
        "        for col, (oh, cols) in onehot_encoders.items():\n",
        "            encoded = oh.transform(X[[col]])\n",
        "            X = X.drop(columns=[col]).join(pd.DataFrame(encoded, columns=cols, index=X.index))\n",
        "\n",
        "    num_cols = X.select_dtypes(include=\"number\").columns.tolist()\n",
        "    if scaler is not None and num_cols:\n",
        "        X[num_cols] = scaler.transform(X[num_cols])\n",
        "\n",
        "\n",
        "    y_pred = pipeline.predict(X)\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred, average=\"weighted\")\n",
        "\n",
        "    return y_pred, acc, f1\n",
        "    \n",
        "df_test = pd.read_csv(\"base_limpa_1.csv\")\n",
        "obj = carregar_pipeline(\"melhor_Random_Forest.pkl\")\n",
        "\n",
        "y_pred, acc, f1 = prever_com_pipeline(df_test, obj)\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"F1-Score:\", f1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
